import pandas as pd
from sklearn.model_selection import train_test_split
from transformers import BertTokenizer
import lightgbm as lgb
from sklearn.metrics import accuracy_score
from nltk.corpus import stopwords
import nltk
import joblib
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import VotingClassifier

import numpy as np

nltk.download('stopwords')
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
def tokenize_text(text):
    return tokenizer.encode_plus(
        text,
        add_special_tokens=True,
        max_length=128,
        padding='max_length',
        return_attention_mask=True,
        return_tensors='np'
    )

def classifier(xtrain, ytrain):
    dt_classifier = DecisionTreeClassifier()
    dt_classifier.fit(xtrain, ytrain)
    joblib.dump(dt_classifier, 'model.pkl')

def preprocessing():
    data = pd.read_csv('articles.csv', encoding='cp1252')

    data['Heading'] = data['Heading'].str.lower()
    data['Heading'] = data['Heading'].str.replace('[^\w\s]', '')  # Punctuations
    data['Heading'] = data['Heading'].str.replace('\d', '')  # Numbers
    sw = stopwords.words('english')
    data['Heading'] = data['Heading'].apply(lambda x: " ".join(x for x in str(x).split() if x not in sw))
    data['tokenized'] = data['Heading'].apply(lambda x: tokenize_text(x)['input_ids'][0])
    from sklearn import preprocessing
    lab_enc = preprocessing.LabelEncoder()
    data['label'] = lab_enc.fit_transform(data['Article_Type'])

    # feat = np.array(data['tokenized'])
    # lab = np.array(data['label'])

    xtrain, xtest, ytrain, ytest = train_test_split(data['tokenized'].tolist(), data['label'], test_size=0.2,
                                                    random_state=42)
    return xtrain, xtest, ytrain, ytest


xtrain, xtest, ytrain, ytest = preprocessing()
# training
classifier(xtrain, ytrain)
# load
model = joblib.load('model.pkl')
predictions = model.predict(xtest)

print('Accuracy score is  ------ > ', accuracy_score(ytest, predictions))
